{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating spark sessions.\n",
    "\n",
    "Spark session is entry point for spark. This contains all configuration. Think like a main method of class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File reading\n",
    "\n",
    "* Spark can read wide verity of files.  Json, CSV, Text files, Parquet and Avro.\n",
    "- Spark has three abstractions. Dataset, Dataframe, RDD.\n",
    "- Rdd - (Resilient Distributed Data) - very initial abstraction of the data. Every operation has to be programmed.\n",
    "- DataFrame - Very efficident data abstraction. Think like RDD + Structure. Any data that has structure, JSON, CSV,XML and Parquet files can be read very easily.\n",
    "- DataSet - Dataset is exactly like DataFrame except that it does not need schema. An improved version of RDD that can also has DataFrame's optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet file format (just for reference)\n",
    "\n",
    "- Parquet (read like parque) is a file format like csv or json or xml. This compresses the data and data will be binary formation (you cannot open and read it unlike csv.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So what is difference between normal file read and spark\n",
    "\n",
    "Spark processes the data in parallel. When you read the data, based on the size it can break the data and process it in parallel. To process in parallel you need to allocate capacity (cores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frame:\n",
    "* DataFrames are the most used abstractions. When i say abstraction, it is a wrapper around the data in memory.\n",
    "\n",
    "- With the dataframe, you can do all processing with lot of pre-built methods that spark comes by default.  \n",
    "\n",
    "- You can also process the data in the form of queries\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What kind of data processing is done in spark.?\n",
    "\n",
    "Spark has two types of operations\n",
    "1. Transformations\n",
    "2. Actions.\n",
    "\n",
    "**Transformations:** any structural changes of the data. example, adding new columns, updating any data, dropping any columns\n",
    "\n",
    "**Actions:** Outcomes of processing. Eg: Saving file, getting count of records, getting all elements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What kind of work Spark can do.\n",
    "\n",
    "* Spark can do something called batch operations and streming/real-time operations.\n",
    "\n",
    "- Batch workload: Its like processing data at once. For eg: running to process all files in a folder\n",
    "\n",
    "Real-time workload: This is called streaming processing. The data comes continously and spark processes them continously. Think like water stream and a fish net. data comes continously and spark job processes on the fly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File reading example. CSV File is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Either use \n",
    "\n",
    "wget https://raw.githubusercontent.com/srini-daruna/temp-repo/master/spark-demo/city_attributes.csv .\n",
    "or\n",
    "download the file directly from the link "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.option(\n",
    "    \"header\",\"true\").csv(\n",
    "    \"./spark-demo/city_attributes.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic operations.\n",
    "\n",
    "Some basic operations to play with are, \n",
    "\n",
    "* printSchema : Shows the structure of the data\n",
    "- count : gives total record count\n",
    "- show: like display in pandas. Shows 20 records sample. The records to show can be adjusted. default value is 20\n",
    "- collect: get all records in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+---------+-----------+\n",
      "|         City|      Country| Latitude|  Longitude|\n",
      "+-------------+-------------+---------+-----------+\n",
      "|    Vancouver|       Canada| 49.24966|-123.119339|\n",
      "|     Portland|United States|45.523449|-122.676208|\n",
      "|San Francisco|United States|37.774929|-122.419418|\n",
      "|      Seattle|United States|47.606209|-122.332069|\n",
      "|  Los Angeles|United States|34.052231|-118.243683|\n",
      "|    San Diego|United States|32.715328|-117.157257|\n",
      "|    Las Vegas|United States|36.174969|-115.137222|\n",
      "|      Phoenix|United States| 33.44838|-112.074043|\n",
      "|  Albuquerque|United States|35.084492|-106.651138|\n",
      "|       Denver|United States|39.739151|-104.984703|\n",
      "|  San Antonio|United States| 29.42412| -98.493629|\n",
      "|       Dallas|United States|32.783058| -96.806671|\n",
      "|      Houston|United States|29.763281| -95.363274|\n",
      "|  Kansas City|United States|39.099731| -94.578568|\n",
      "|  Minneapolis|United States|44.979969|  -93.26384|\n",
      "|  Saint Louis|United States| 38.62727| -90.197891|\n",
      "|      Chicago|United States|41.850029| -87.650047|\n",
      "|    Nashville|United States| 36.16589| -86.784439|\n",
      "| Indianapolis|United States|39.768379| -86.158043|\n",
      "|      Atlanta|United States|33.749001| -84.387978|\n",
      "+-------------+-------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can filter the data like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+---------+----------+\n",
      "|        City|      Country| Latitude| Longitude|\n",
      "+------------+-------------+---------+----------+\n",
      "|Indianapolis|United States|39.768379|-86.158043|\n",
      "+------------+-------------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter(\"City = 'Indianapolis'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+---------+-----------+--------------+\n",
      "|         City|      Country| Latitude|  Longitude|    new_column|\n",
      "+-------------+-------------+---------+-----------+--------------+\n",
      "|    Vancouver|       Canada| 49.24966|-123.119339|this is sample|\n",
      "|     Portland|United States|45.523449|-122.676208|this is sample|\n",
      "|San Francisco|United States|37.774929|-122.419418|this is sample|\n",
      "|      Seattle|United States|47.606209|-122.332069|this is sample|\n",
      "|  Los Angeles|United States|34.052231|-118.243683|this is sample|\n",
      "|    San Diego|United States|32.715328|-117.157257|this is sample|\n",
      "|    Las Vegas|United States|36.174969|-115.137222|this is sample|\n",
      "|      Phoenix|United States| 33.44838|-112.074043|this is sample|\n",
      "|  Albuquerque|United States|35.084492|-106.651138|this is sample|\n",
      "|       Denver|United States|39.739151|-104.984703|this is sample|\n",
      "|  San Antonio|United States| 29.42412| -98.493629|this is sample|\n",
      "|       Dallas|United States|32.783058| -96.806671|this is sample|\n",
      "|      Houston|United States|29.763281| -95.363274|this is sample|\n",
      "|  Kansas City|United States|39.099731| -94.578568|this is sample|\n",
      "|  Minneapolis|United States|44.979969|  -93.26384|this is sample|\n",
      "|  Saint Louis|United States| 38.62727| -90.197891|this is sample|\n",
      "|      Chicago|United States|41.850029| -87.650047|this is sample|\n",
      "|    Nashville|United States| 36.16589| -86.784439|this is sample|\n",
      "| Indianapolis|United States|39.768379| -86.158043|this is sample|\n",
      "|      Atlanta|United States|33.749001| -84.387978|this is sample|\n",
      "+-------------+-------------+---------+-----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## You can new column like this\n",
    "# you need to use lit to add a constant. lit means literal\n",
    "from pyspark.sql.functions import lit\n",
    "df2 = df1.withColumn(\"new_column\",lit(\"this is sample\"))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+---------+--------------+\n",
      "|         City|      Country| Latitude|    new_column|\n",
      "+-------------+-------------+---------+--------------+\n",
      "|    Vancouver|       Canada| 49.24966|this is sample|\n",
      "|     Portland|United States|45.523449|this is sample|\n",
      "|San Francisco|United States|37.774929|this is sample|\n",
      "|      Seattle|United States|47.606209|this is sample|\n",
      "|  Los Angeles|United States|34.052231|this is sample|\n",
      "|    San Diego|United States|32.715328|this is sample|\n",
      "|    Las Vegas|United States|36.174969|this is sample|\n",
      "|      Phoenix|United States| 33.44838|this is sample|\n",
      "|  Albuquerque|United States|35.084492|this is sample|\n",
      "|       Denver|United States|39.739151|this is sample|\n",
      "|  San Antonio|United States| 29.42412|this is sample|\n",
      "|       Dallas|United States|32.783058|this is sample|\n",
      "|      Houston|United States|29.763281|this is sample|\n",
      "|  Kansas City|United States|39.099731|this is sample|\n",
      "|  Minneapolis|United States|44.979969|this is sample|\n",
      "|  Saint Louis|United States| 38.62727|this is sample|\n",
      "|      Chicago|United States|41.850029|this is sample|\n",
      "|    Nashville|United States| 36.16589|this is sample|\n",
      "| Indianapolis|United States|39.768379|this is sample|\n",
      "|      Atlanta|United States|33.749001|this is sample|\n",
      "+-------------+-------------+---------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop column\n",
    "df2.drop(\"Longitude\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|         City|      Country|\n",
      "+-------------+-------------+\n",
      "|    Vancouver|       Canada|\n",
      "|     Portland|United States|\n",
      "|San Francisco|United States|\n",
      "|      Seattle|United States|\n",
      "|  Los Angeles|United States|\n",
      "|    San Diego|United States|\n",
      "|    Las Vegas|United States|\n",
      "|      Phoenix|United States|\n",
      "|  Albuquerque|United States|\n",
      "|       Denver|United States|\n",
      "|  San Antonio|United States|\n",
      "|       Dallas|United States|\n",
      "|      Houston|United States|\n",
      "|  Kansas City|United States|\n",
      "|  Minneapolis|United States|\n",
      "|  Saint Louis|United States|\n",
      "|      Chicago|United States|\n",
      "|    Nashville|United States|\n",
      "| Indianapolis|United States|\n",
      "|      Atlanta|United States|\n",
      "+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Selecting only required columns\n",
    "\n",
    "df1.select(\"City\",\"Country\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+---------+-----------+\n",
      "|  RenamedCity|      Country| Latitude|  Longitude|\n",
      "+-------------+-------------+---------+-----------+\n",
      "|    Vancouver|       Canada| 49.24966|-123.119339|\n",
      "|     Portland|United States|45.523449|-122.676208|\n",
      "|San Francisco|United States|37.774929|-122.419418|\n",
      "|      Seattle|United States|47.606209|-122.332069|\n",
      "|  Los Angeles|United States|34.052231|-118.243683|\n",
      "|    San Diego|United States|32.715328|-117.157257|\n",
      "|    Las Vegas|United States|36.174969|-115.137222|\n",
      "|      Phoenix|United States| 33.44838|-112.074043|\n",
      "|  Albuquerque|United States|35.084492|-106.651138|\n",
      "|       Denver|United States|39.739151|-104.984703|\n",
      "|  San Antonio|United States| 29.42412| -98.493629|\n",
      "|       Dallas|United States|32.783058| -96.806671|\n",
      "|      Houston|United States|29.763281| -95.363274|\n",
      "|  Kansas City|United States|39.099731| -94.578568|\n",
      "|  Minneapolis|United States|44.979969|  -93.26384|\n",
      "|  Saint Louis|United States| 38.62727| -90.197891|\n",
      "|      Chicago|United States|41.850029| -87.650047|\n",
      "|    Nashville|United States| 36.16589| -86.784439|\n",
      "| Indianapolis|United States|39.768379| -86.158043|\n",
      "|      Atlanta|United States|33.749001| -84.387978|\n",
      "+-------------+-------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# renaming column\n",
    "df1.withColumnRenamed(\"City\",\"RenamedCity\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can do joins, unions and many more with spark\n",
    "\n",
    "#### to join, you need to two data frames. Here i am creating two data frames and joining them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe1 = spark.read.option(\"header\",\"true\").csv(\"./spark-demo/imdb_data_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe2 = spark.read.option(\"header\",\"true\").option(\"delimiter\",\";\").csv(\"./spark-demo/AllMoviesDetailsCleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You need to specify on which columns you want to join.\n",
    "Similar to a SQL Query\n",
    "\n",
    "**Example SQL Query:** We write SQL Query to join two tables like below. We will use same understanding with dataframes.\n",
    "\n",
    "* Select * from table1 a JOIN table2 b ON a.some_column = b.some_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- imdb_title_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- date_published: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- writer: string (nullable = true)\n",
      " |-- production_company: string (nullable = true)\n",
      " |-- actors: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- avg_vote: string (nullable = true)\n",
      " |-- votes: string (nullable = true)\n",
      " |-- budget: string (nullable = true)\n",
      " |-- usa_gross_income: string (nullable = true)\n",
      " |-- worlwide_gross_income: string (nullable = true)\n",
      " |-- metascore: string (nullable = true)\n",
      " |-- reviews_from_users: string (nullable = true)\n",
      " |-- reviews_from_critics: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- budget: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- imdb_id: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- revenue: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- spoken_languages: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- tagline: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- vote_average: string (nullable = true)\n",
      " |-- vote_count: string (nullable = true)\n",
      " |-- production_companies_number: string (nullable = true)\n",
      " |-- production_countries_number: string (nullable = true)\n",
      " |-- spoken_languages_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------------------+---------+-----------------+--------------------+--------------------+----------+--------------------+--------------------+------------+--------+-------+----------------+--------+--------------------+--------------------+------------+----------+---------------------------+---------------------------+-----------------------+-------------+--------------------+--------------------+----+--------------+--------------------+--------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------+------+-----------+----------------+---------------------+---------+------------------+--------------------+\n",
      "| id|  budget|              genres|  imdb_id|original_language|      original_title|            overview|popularity|production_companies|production_countries|release_date| revenue|runtime|spoken_languages|  status|             tagline|               title|vote_average|vote_count|production_companies_number|production_countries_number|spoken_languages_number|imdb_title_id|               title|      original_title|year|date_published|               genre|duration|     country|            language|            director|              writer|  production_company|              actors|         description|avg_vote| votes|     budget|usa_gross_income|worlwide_gross_income|metascore|reviews_from_users|reviews_from_critics|\n",
      "+---+--------+--------------------+---------+-----------------+--------------------+--------------------+----------+--------------------+--------------------+------------+--------+-------+----------------+--------+--------------------+--------------------+------------+----------+---------------------------+---------------------------+-----------------------+-------------+--------------------+--------------------+----+--------------+--------------------+--------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------+------+-----------+----------------+---------------------+---------+------------------+--------------------+\n",
      "| 19|92620000|Drama|Science Fic...|tt0017136|               de|          Metropolis|In a futuristic c...|  3.669986|  Paramount Pictures|             Germany|  10/01/1927|  650422|    153|     No Language|Released|There can be no u...|          Metropolis|         8.0|       614|                          2|                          1|                      1|    tt0017136|          Metropolis|          Metropolis|1927|    1928-10-01|       Drama, Sci-Fi|     153|     Germany|              German|          Fritz Lang|Thea von Harbou, ...|Universum Film (UFA)|Alfred Abel, Gust...|In a futuristic c...|     8.3|156076|DEM 6000000|       $ 1236166|            $ 1349711|     98.0|             495.0|               208.0|\n",
      "|136|       0|        Drama|Horror|tt0022913|               en|              Freaks|A circus' beautif...|  1.125978|Metro-Goldwyn-May...|United States of ...|  20/02/1932|       0|     64|         English|Released|The love story of...|              Freaks|         7.7|       209|                          1|                          1|                      3|    tt0022913|              Freaks|              Freaks|1932|    1932-02-20|       Drama, Horror|      64|         USA|English, German, ...|        Tod Browning|Clarence Aaron 'T...|Metro-Goldwyn-May...|Wallace Ford, Lei...|A circus' beautif...|     7.9| 41173|   $ 310607|            null|               $ 4072|     80.0|             283.0|               158.0|\n",
      "|138|  355000|              Horror|tt0021814|               en|             Dracula|The legend of vam...|  1.283226|  Universal Pictures|United States of ...|  12/02/1931| 1012189|     72|         Deutsch|Released|The story of the ...|             Dracula|         7.1|       233|                          1|                          1|                      3|    tt0021814|             Dracula|             Dracula|1931|    1931-02-14|Drama, Fantasy, H...|      75|         USA|English, Hungaria...|Tod Browning, Kar...|Bram Stoker, Hami...|  Universal Pictures|Bela Lugosi, Hele...|The ancient vampi...|     7.5| 45054|   $ 355000|            null|              $ 85204|     null|             556.0|               163.0|\n",
      "|143| 1250000|           Drama|War|tt0020629|               en|All Quiet on the ...|A young soldier f...|  1.984822|  Universal Pictures|United States of ...|  21/04/1930|       0|    133|         English|Released|They left for war...|All Quiet on the ...|         7.5|       150|                          1|                          1|                      4|    tt0020629|All'ovest niente ...|All Quiet on the ...|1930|    1956-03-14|          Drama, War|     152|         USA|English, French, ...|     Lewis Milestone|Erich Maria Remar...|  Universal Pictures|Louis Wolheim, Le...|A German youth ea...|     8.0| 56356|  $ 1200000|            null|                 null|     91.0|             240.0|               102.0|\n",
      "|228|       0|               Drama|tt0020697|               de|     Der blaue Engel|The Blue Angel fo...|  0.317506|Universum Film (UFA)|             Germany|  31/03/1930|       0|    108|         English|Released|                null|      The Blue Angel|         7.5|        49|                          1|                          1|                      3|    tt0020697|    L'angelo azzurro|     Der blaue Engel|1930|    1931-02-25|        Drama, Music|     104|     Germany|German, English, ...| Josef von Sternberg|Heinrich Mann, Ca...|Universum Film (UFA)|Emil Jannings, Ma...|An elderly profes...|     7.7| 13311|       null|            null|               $ 4410|     88.0|             104.0|               101.0|\n",
      "|234|   18000|Drama|Horror|Thri...|tt0010323|               de|Das Cabinet des D...|The Cabinet of Dr...|  1.572642|Decla Film Gesell...|             Germany|  25/02/1920|       0|     78|     No Language|Released|You must become C...|The Cabinet of Dr...|         7.7|       247|                          1|                          1|                      1|    tt0010323|Il gabinetto del ...|Das Cabinet des D...|1920|    1920-02-27|Fantasy, Horror, ...|      76|     Germany|              German|        Robert Wiene|Carl Mayer, Hans ...|    Decla-Bioscop AG|Werner Krauss, Co...|Hypnotist Dr. Cal...|     8.1| 55601|    $ 18000|          $ 8811|               $ 8811|     null|             237.0|               160.0|\n",
      "|347|       0|               Drama|tt0020163|               de| Menschen am Sonntag|A semi-documentar...|  2.417317|   Filmstudio Berlin|             Germany|  04/02/1930|       0|     74|     No Language|Released|                null|    People on Sunday|         7.0|        15|                          2|                          1|                      1|    tt0020163|  Uomini di domenica| Menschen am Sonntag|1930|    1930-02-04|Comedy, Drama, Ro...|      73|     Germany|                null|Robert Siodmak, E...|Curt Siodmak, Bil...|    Film Studio 1929|Erwin Splettstöße...|Two men and two w...|     7.4|  2649|       null|            null|                 null|     null|              19.0|                46.0|\n",
      "|543|       0|Drama|Thriller|Crime|tt0019702|               en|           Blackmail|Alice's boyfriend...|  0.188931|British Internati...|      United Kingdom|  30/06/1929|       0|     84|         English|Released|See and Hear It -...|           Blackmail|         6.7|        40|                          1|                          1|                      1|    tt0019702|             Ricatto|           Blackmail|1929|    1929-10-06|     Crime, Thriller|      85|          UK|             English|    Alfred Hitchcock|Charles Bennett, ...|British Internati...|Anny Ondra, Sara ...|After killing a m...|     7.0|  9412|       null|            null|                 null|     null|              98.0|                65.0|\n",
      "|618|  110000|Drama|History|Rom...|tt0004972|               en|The Birth of a Na...|The Birth of A Na...|  0.360068|      Epoch Film Co.|United States of ...|  08/02/1915|11000000|    190|     No Language|Released|The fiery cross o...|The Birth of a Na...|         6.3|        91|                          1|                          1|                      1|    tt0004972|Nascita di una na...|The Birth of a Na...|1915|    1915-03-21| Drama, History, War|     195|         USA|                None|       D.W. Griffith|Thomas Dixon Jr.,...|David W. Griffith...|Henry B. Walthall...|The Stoneman fami...|     6.3| 22213|   $ 100000|            null|                 null|     null|             368.0|                97.0|\n",
      "|631|       0|       Drama|Romance|tt0018455|               en|Sunrise: A Song o...|A married farmer ...|  1.540355|Fox Film Corporation|United States of ...|  23/09/1927|       0|     94|            none|Released|An Artistic Maste...|Sunrise: A Song o...|         7.8|       137|                          1|                          1|                      0|    tt0018455|              Aurora|Sunrise: A Song o...|1927|    1928-03-31|      Drama, Romance|      94|         USA|             English|         F.W. Murnau|Carl Mayer, Herma...|Fox Film Corporation|George O'Brien, J...|An allegorical ta...|     8.1| 46069|   $ 200000|            null|             $ 121107|     null|             250.0|               186.0|\n",
      "|643|       0|       Drama|History|tt0015648|               ru|Броненосец «Потём...|A dramatized acco...|  1.122584| Goskino Productions|              Russia|  24/12/1925|   45100|     75|         Pусский|Released|Revolution is the...| Battleship Potemkin|         7.5|       181|                          2|                          1|                      1|    tt0015648|La corazzata Pote...|Bronenosets Potemkin|1925|    1960-04-07|Drama, History, T...|      75|Soviet Union|             Russian|Sergei M. Eisenstein|    Nina Agadzhanova|             Goskino|Aleksandr Antonov...|In the midst of t...|     8.0| 51775|       null|         $ 51198|              $ 61389|     null|             210.0|                85.0|\n",
      "|653|       0|Drama|Fantasy|Horror|tt0013442|               de|Nosferatu, eine S...|\"Vampire Count Or...|  1.315536|        Jofa Atelier|             Germany|  06/03/1922|       0|     94|         Deutsch|Released|A symphony of horror|           Nosferatu|         7.7|       338|                          2|                          1|                      1|    tt0013442|Nosferatu - Il va...|Nosferatu, eine S...|1922|    1922-03-04|     Fantasy, Horror|      94|     Germany|              German|         F.W. Murnau|Henrik Galeen, Br...|Jofa-Atelier Berl...|Max Schreck, Gust...|Vampire Count Orl...|     7.9| 86620|       null|            null|              $ 19054|     null|             419.0|               202.0|\n",
      "|697|       0|   Documentary|Drama|tt0018217|               ru|             Oktyabr|October is Sergei...|  0.150224|             Sovkino|              Russia|  14/03/1928|       0|     94|         Pусский|Released|                null|October (Ten Days...|         6.5|        23|                          1|                          1|                      1|    tt0018217|            Ottobre!|             Oktyabr|1927|    1928-09-24|      Drama, History|     142|Soviet Union|                null|Grigoriy Aleksand...|Sergei M. Eisenst...|             Sovkino|Nikolay Popov, Va...|A large-scale vie...|     7.5|  6877|       null|            null|                 null|     null|              50.0|                23.0|\n",
      "|701|       0| Comedy|Drama|Family|tt0014341|               en|     Our Hospitality|A man returns to ...|  0.218139|Joseph M. Schenck...|United States of ...|  19/11/1923|       0|     73|         English|Released|A Comedy with a H...|     Our Hospitality|         7.7|        43|                          1|                          1|                      1|    tt0014341|Accidenti che osp...|     Our Hospitality|1923|    1925-11-27|Comedy, Romance, ...|      65|         USA|             English|John G. Blystone,...|Jean C. Havez, Cl...|Joseph M. Schenck...|Buster Keaton, Na...|A man returns to ...|     7.8|  9902|       null|            null|                 null|     null|              54.0|                47.0|\n",
      "|780|       0|       Drama|History|tt0019254|               fr|La passion de Jea...|A classic of the ...|   1.27167|Société générale ...|              France|  21/04/1928|       0|     82|        Français|Released|An Immortal Scree...|The Passion of Jo...|         8.1|       143|                          1|                          1|                      1|    tt0019254|La passione di Gi...|La passion de Jea...|1928|    1929-01-18|Biography, Drama,...|     110|      France|              French| Carl Theodor Dreyer|Joseph Delteil, C...|Société générale ...|Maria Falconetti,...|In 1431, Jeanne d...|     8.1| 45823|       null|         $ 21877|              $ 21877|     null|             195.0|               137.0|\n",
      "|785|       0|               Drama|tt0023104|               de|Kuhle Wampe oder:...|Kuhle Wampe is a ...|  0.000164|          Prometheus|             Germany|  14/05/1932|       0|     74|         Deutsch|Released|                null|To Whom Does the ...|         6.6|         5|                          2|                          1|                      1|    tt0023104|Kuhle Wampe oder:...|Kuhle Wampe oder:...|1932|    1932-05-30|               Drama|      71|     Germany|              German|        Slatan Dudow|Bertolt Brecht, E...|Prometheus-Film-V...|Hertha Thiele, Er...|During Great Depr...|     6.6|   614|       null|            null|                 null|     null|               7.0|                 6.0|\n",
      "|832|       0|Drama|Action|Thri...|tt0022100|               de|                   M|In this classic G...|  2.962145|        Nero-Film AG|             Germany|  11/05/1931|       0|    117|         Deutsch|Released|                null|                   M|         8.0|       419|                          1|                          1|                      1|    tt0022100|M - Il mostro di ...|M - Eine Stadt su...|1931|    1960-08-26|Crime, Mystery, T...|     117|     Germany|              German|          Fritz Lang|Thea von Harbou, ...|        Nero-Film AG|Peter Lorre, Elle...|When the police i...|     8.3|139271|       null|         $ 35566|              $ 35566|     null|             359.0|               155.0|\n",
      "|835|       0|     Science Fiction|tt0022869|               de|F.P.1 antwortet n...|F.P.1 is a huge a...|  0.002649|                none|             Germany|  22/12/1932|       0|    114|         Deutsch|Released|                null|F.P.1 Doesn't Answer|         0.0|         0|                          0|                          1|                      1|    tt0022869|   FP 1 non risponde|F.P.1 antwortet n...|1932|    1932-12-22|              Sci-Fi|     114|     Germany|              German|          Karl Hartl|Walter Reisch, Cu...|Universum Film (UFA)|Hans Albers, Sybi...|Urged by famous a...|     6.3|   201|       null|            null|                 null|     null|               6.0|                 4.0|\n",
      "|885|       0|       Drama|Romance|tt0018839|               en|The Docks of New ...|A blue-collar wor...|  0.081869|  Paramount Pictures|United States of ...|  16/09/1928|       0|     76|     No Language|Released|                null|The Docks of New ...|         6.8|        12|                          1|                          1|                      1|    tt0018839|I dannati dell'oc...|The Docks of New ...|1928|    1928-09-29|Crime, Drama, Fil...|      76|         USA|             English| Josef von Sternberg|Jules Furthman, J...|  Paramount Pictures|George Bancroft, ...|A blue-collar wor...|     7.5|  3860|       null|            null|                 null|     null|              34.0|                51.0|\n",
      "|899|       0|       Drama|Romance|tt0009968|               en|     Broken Blossoms|Broken Blossoms i...|  0.256136|      United Artists|United States of ...|  13/05/1919|       0|     90|     No Language|Released|                null|     Broken Blossoms|         6.9|        35|                          2|                          1|                      1|    tt0009968|     Giglio infranto|Broken Blossoms o...|1919|    1923-02-23|      Drama, Romance|      90|         USA|                null|       D.W. Griffith|Thomas Burke, D.W...|D.W. Griffith Pro...|Lillian Gish, Ric...|A frail waif, abu...|     7.3|  9241|    $ 88000|            null|                 null|     null|              89.0|                78.0|\n",
      "+---+--------+--------------------+---------+-----------------+--------------------+--------------------+----------+--------------------+--------------------+------------+--------+-------+----------------+--------+--------------------+--------------------+------------+----------+---------------------------+---------------------------+-----------------------+-------------+--------------------+--------------------+----+--------------+--------------------+--------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------+------+-----------+----------------+---------------------+---------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "dataframe2.join(dataframe1, col(\"imdb_id\") == col(\"imdb_title_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|    budget|\n",
      "+----------+\n",
      "|      null|\n",
      "|    $ 2250|\n",
      "|      null|\n",
      "|   $ 45000|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "| ITL 45000|\n",
      "|ROL 400000|\n",
      "|   $ 30000|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|      null|\n",
      "|    $ 5700|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "one_data_for_union = dataframe1.select(\"budget\")\n",
    "second_data_for_union = dataframe2.select(\"budget\")\n",
    "\n",
    "result = one_data_for_union.union(second_data_for_union)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
